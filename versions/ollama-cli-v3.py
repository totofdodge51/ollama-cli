#!/usr/bin/env python3
"""
Ollama CLI v2 - Assistant LLM interactif amÃ©liorÃ© avec des capacitÃ©s avancÃ©es de gestion de fichiers.
"""

import os
import sys
import json
import argparse
import requests
from pathlib import Path
from typing import List, Optional, Tuple
import readline
import atexit
import subprocess
import difflib
import xml.etree.ElementTree as ET
import re

# Importations de la bibliothÃ¨que Rich pour une interface utilisateur riche
from rich.console import Console
from rich.markdown import Markdown
from rich.syntax import Syntax
from rich.panel import Panel
from rich.prompt import Prompt, Confirm
from rich.table import Table
from rich.live import Live
from rich.spinner import Spinner
from rich.text import Text

# Initialisation de la console Rich pour un affichage esthÃ©tique
console = Console()

# Fichiers pour l'historique et le contexte
HISTORY_FILE = Path.home() / ".ollama_cli_history"
CONTEXT_FILE = Path.home() / ".ollama_cli_context.json"

# --- AMÃ‰LIORATION : Logo ASCII Art "OLLAMA-CLI" corrigÃ© ---
ASCII_LOGO = r"""
 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—     â–ˆâ–ˆâ•—     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—     â–ˆâ–ˆâ•—â–ˆâ–ˆâ•—
â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—    â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘â•šâ•â•
â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘    â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•—
 â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•     â•šâ•â•â•šâ•â•  â•šâ•â•     â•šâ•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•šâ•â•
"""

class OllamaAPI:
    """Wrapper pour les appels Ã  l'API d'Ollama"""

    def __init__(self, base_url: str = "http://localhost:11434"):
        self.base_url = base_url
        self.model = "llama3"  # ModÃ¨le par dÃ©faut
        self.system_prompt_template = """Vous Ãªtes un assistant de dÃ©veloppement expert dans un terminal de ligne de commande.

Votre but est d'aider l'utilisateur avec son code. Les fichiers suivants sont actuellement chargÃ©s en contexte : {loaded_files}.

- Pour une conversation gÃ©nÃ©rale, rÃ©pondez de maniÃ¨re claire et concise.
- Pour **crÃ©er un nouveau fichier**, utilisez le format <plan> et <code>.
- Pour **modifier un ou plusieurs fichiers existants**, rÃ©pondez en utilisant **uniquement** le format XML suivant. Ne mettez AUCUN texte avant ou aprÃ¨s le bloc <file_modifications>.

<file_modifications>
  <file path="chemin/vers/fichier1.py">
  <![CDATA[
Le contenu INTEGRAL et MODIFIÃ‰ du fichier1.py va ici.
]]>
  </file>
  <file path="chemin/vers/fichier2.js">
  <![CDATA[
Le contenu INTEGRAL et MODIFIÃ‰ du fichier2.js va ici.
]]>
  </file>
</file_modifications>

- Fournissez toujours le contenu complet du fichier, pas seulement un extrait ou un diff.
- L'utilisateur verra un diff des changements et devra confirmer avant d'enregistrer."""

    def get_system_prompt(self, loaded_files: List[str]) -> str:
        """Formate le prompt systÃ¨me avec les fichiers actuellement chargÃ©s."""
        files_str = ", ".join(loaded_files) if loaded_files else "aucun"
        return self.system_prompt_template.format(loaded_files=files_str)

    def list_models(self) -> List[str]:
        """Liste les modÃ¨les Ollama disponibles."""
        try:
            response = requests.get(f"{self.base_url}/api/tags")
            response.raise_for_status()
            models = response.json().get("models", [])
            return [model["name"] for model in models]
        except requests.exceptions.RequestException as e:
            console.print(f"[red]Erreur de connexion Ã  l'API Ollama : {e}[/red]")
            return []

    def generate(self, prompt: str, system_prompt: str, context: Optional[List] = None, stream: bool = True) -> str:
        """GÃ©nÃ¨re une rÃ©ponse depuis Ollama, en stream par dÃ©faut."""
        payload = {
            "model": self.model,
            "prompt": prompt,
            "system": system_prompt,
            "stream": stream,
            "context": context or []
        }

        try:
            response = requests.post(f"{self.base_url}/api/generate", json=payload, stream=stream)
            response.raise_for_status()

            full_response = ""
            if stream:
                spinner = Spinner("dots", " L'assistant rÃ©flÃ©chit...")
                with Live(spinner, refresh_per_second=10, transient=True) as live:
                    for line in response.iter_lines():
                        if line:
                            data = json.loads(line)
                            chunk = data.get("response", "")
                            full_response += chunk
                            live.update(Markdown(full_response), refresh=True)

                            if data.get("done", False):
                                self.last_context = data.get("context", [])
                                break
                console.print(Markdown(full_response))
                return full_response
            else:
                data = response.json()
                full_response = data.get("response", "")
                self.last_context = data.get("context", [])
                return full_response

        except requests.exceptions.RequestException as e:
            console.print(f"[red]Erreur lors de l'appel Ã  l'API Ollama : {e}[/red]")
            return ""
        except json.JSONDecodeError:
            console.print("[red]Erreur: RÃ©ponse invalide de l'API Ollama.[/red]")
            return ""

class FileHandler:
    """GÃ¨re les opÃ©rations sur les fichiers et l'affichage des modifications."""

    @staticmethod
    def read_file(filepath: Path) -> Tuple[bool, str]:
        """Lit le contenu d'un fichier."""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                return True, f.read()
        except Exception as e:
            return False, str(e)

    @staticmethod
    def write_file(filepath: Path, content: str) -> Tuple[bool, str]:
        """Ã‰crit du contenu dans un fichier."""
        try:
            filepath.parent.mkdir(parents=True, exist_ok=True)
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            return True, f"Fichier sauvegardÃ© : {filepath}"
        except Exception as e:
            return False, str(e)

    @staticmethod
    def show_diff(original: str, modified: str, filepath: str) -> None:
        """Affiche un diff colorÃ© entre deux versions de contenu."""
        diff = difflib.unified_diff(
            original.splitlines(keepends=True),
            modified.splitlines(keepends=True),
            fromfile=f"{filepath} (original)",
            tofile=f"{filepath} (modifiÃ©)"
        )

        console.print(Panel(f"Changements proposÃ©s pour [bold cyan]{filepath}[/bold cyan]", border_style="yellow"))
        diff_lines = list(diff)
        if not diff_lines:
            console.print("[dim]Aucun changement dÃ©tectÃ©.[/dim]")
            return

        for line in diff_lines:
            if line.startswith('+'):
                console.print(f"[green]{line}[/green]", end="")
            elif line.startswith('-'):
                console.print(f"[red]{line}[/red]", end="")
            elif line.startswith('@@'):
                console.print(f"[yellow]{line}[/yellow]", end="")
            else:
                console.print(line, end="")

class OllamaCLI:
    """Application CLI principale."""

    def __init__(self):
        self.api = OllamaAPI()
        self.file_handler = FileHandler()
        self.context = []
        self.conversation_history = []
        self.working_directory = Path.cwd()
        self.loaded_files = {}
        self.setup_readline()

    def setup_readline(self):
        """Configure readline pour l'historique des commandes."""
        if HISTORY_FILE.exists():
            readline.read_history_file(HISTORY_FILE)
        readline.set_history_length(1000)
        atexit.register(readline.write_history_file, HISTORY_FILE)

    def load_context(self):
        """Charge le contexte de la conversation prÃ©cÃ©dente depuis un fichier."""
        if CONTEXT_FILE.exists():
            try:
                with open(CONTEXT_FILE, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.context = data.get("context", [])
                    self.conversation_history = data.get("history", [])
                    console.print("[dim]Contexte de la conversation prÃ©cÃ©dente chargÃ©.[/dim]")
            except (json.JSONDecodeError, IOError) as e:
                console.print(f"[yellow]Avertissement : Impossible de charger le contexte : {e}[/yellow]")
                self.context = []
                self.conversation_history = []

    def save_context(self):
        """Sauvegarde le contexte de la conversation actuelle dans un fichier."""
        try:
            with open(CONTEXT_FILE, 'w', encoding='utf-8') as f:
                context_to_save = {
                    "context": self.context,
                    "history": self.conversation_history[-20:]
                }
                json.dump(context_to_save, f, indent=2)
        except IOError as e:
            console.print(f"[yellow]Avertissement : Impossible de sauvegarder le contexte : {e}[/yellow]")

    def select_model(self) -> bool:
        """Permet Ã  l'utilisateur de sÃ©lectionner un modÃ¨le Ollama."""
        console.print(Panel("ğŸ¤– ModÃ¨les Disponibles", border_style="blue"))
        models = self.api.list_models()
        if not models:
            console.print("[red]Aucun modÃ¨le Ollama trouvÃ©. Assurez-vous qu'Ollama est en cours d'exÃ©cution et que des modÃ¨les sont installÃ©s (ex: `ollama pull llama3`).[/red]")
            return False

        table = Table(show_header=True, header_style="bold magenta")
        table.add_column("Index", style="cyan")
        table.add_column("Nom du ModÃ¨le", style="green")

        for i, model in enumerate(models, 1):
            table.add_row(str(i), model)

        console.print(table)

        choices = [str(i) for i in range(1, len(models) + 1)]
        choice = Prompt.ask("SÃ©lectionnez un modÃ¨le", choices=choices, default="1")

        idx = int(choice) - 1
        self.api.model = models[idx]
        console.print(f"[green]âœ“ ModÃ¨le sÃ©lectionnÃ© : [bold]{self.api.model}[/bold][/green]")
        return True

    def handle_command(self, command: str) -> Tuple[bool, Optional[str]]:
        """GÃ¨re les commandes spÃ©ciales commenÃ§ant par '/'.

        Returns:
            Tuple[bool, Optional[str]]: (continue_loop, processed_input)
        """
        parts = command.split()
        cmd = parts[0].lower()

        if cmd in ["/quit", "/exit", "/q"]:
            console.print("Au revoir !")
            return False, None
        elif cmd == "/help":
            self.show_help()
            return True, None
        elif cmd == "/clear":
            self.clear_context()
            console.print("[green]Contexte effacÃ©.[/green]")
            return True, None
        elif cmd == "/model":
            self.select_model()
            return True, None
        elif cmd == "/load":
            if len(parts) > 1:
                self.load_file(Path(" ".join(parts[1:])))
            else:
                console.print("[red]Usage: /load <filepath>[/red]")
            return True, None
        elif cmd == "/edit":
            if len(parts) > 1:
                self.edit_file(Path(" ".join(parts[1:])))
            else:
                console.print("[red]Usage: /edit <filepath>[/red]")
            return True, None
        elif cmd == "/paste":
            pasted_text = self.get_pasted_input()
            return True, pasted_text
        elif cmd == "/run":
            if len(parts) > 1:
                self.run_command(" ".join(parts[1:]))
            else:
                console.print("[red]Usage: /run <command>[/red]")
            return True, None
        elif cmd == "/files":
            self.list_loaded_files()
            return True, None
        elif cmd == "/pwd":
            console.print(f"[cyan]RÃ©pertoire actuel : {self.working_directory}[/cyan]")
            return True, None
        elif cmd == "/cd":
            if len(parts) > 1:
                self.change_directory(Path(" ".join(parts[1:])))
            else:
                console.print("[red]Usage: /cd <directory>[/red]")
            return True, None
        else:
            console.print(f"[red]Commande inconnue : {cmd}. Tapez /help pour la liste.[/red]")
            return True, None

    def clear_context(self):
        self.context = []
        self.conversation_history = []
        self.loaded_files = {}

    def show_help(self):
        help_text = """
#  Aide de Ollama CLI v3

## Commandes de Chat
- **`/quit`, `/exit`, `/q`**: Quitter l'application.
- **`/clear`**: Effacer l'historique de la conversation et les fichiers chargÃ©s.
- **`/model`**: SÃ©lectionner un autre modÃ¨le Ollama.
- **`/paste`**: Activer le mode collage pour envoyer du code ou du texte multiligne.

## Commandes de Fichiers
- **`/load <fichier>`**: Charger un fichier et le visualiser dans un pager (comme `less`).
- **`/edit <fichier>`**: Lancer une session d'Ã©dition assistÃ©e par l'IA sur un fichier.
- **`/files`**: Lister les fichiers actuellement chargÃ©s en mÃ©moire.
- **`/pwd`**: Afficher le rÃ©pertoire de travail actuel.
- **`/cd <dossier>`**: Changer de rÃ©pertoire de travail.

## Commandes SystÃ¨me
- **`/run <commande>`**: ExÃ©cuter une commande shell.
- **`/help`**: Afficher ce message d'aide.
        """
        console.print(Panel(Markdown(help_text), title=" Aide ", border_style="green"))

    def load_file(self, filepath: Path):
        full_path = self.working_directory / filepath
        if not full_path.exists():
            console.print(f"[red]Erreur : Le fichier {full_path} n'existe pas.[/red]")
            return

        success, content = self.file_handler.read_file(full_path)

        if success:
            self.loaded_files[str(filepath)] = content
            console.print(Panel(
                f"ğŸ“‚ Fichier [bold cyan]{filepath}[/bold cyan] chargÃ© en contexte ({len(content)} caractÃ¨res).",
                title="Chargement rÃ©ussi",
                border_style="blue"
            ))
            # Affiche le contenu dans un pager pour une meilleure lisibilitÃ©
            self._display_with_pager(filepath, content)
        else:
            console.print(f"[red]Erreur de chargement : {content}[/red]")

    def _display_with_pager(self, filepath: Path, content: str):
        """Affiche le contenu du fichier dans un pager comme `less` avec coloration syntaxique."""
        lexer = self.guess_lexer(filepath, code=content)
        syntax = Syntax(content, lexer, theme="monokai", line_numbers=True)

        # Utilise une console temporaire pour capturer la sortie colorÃ©e
        temp_console = Console(record=True, file=open(os.devnull, 'w'))
        temp_console.print(syntax)
        output = temp_console.export_text()

        try:
            # Utilise less avec des options pour les couleurs ANSI et un comportement agrÃ©able
            subprocess.run(
                ["less", "-R", "-F", "-X"],
                input=output,
                text=True,
                check=True
            )
        except FileNotFoundError:
            console.print("[yellow]Avertissement : Commande 'less' non trouvÃ©e. Affichage d'un aperÃ§u.[/yellow]")
            preview = Syntax(content[:1000] + ("..." if len(content) > 1000 else ""), lexer, theme="monokai", line_numbers=True)
            console.print(Panel(preview, title=f"AperÃ§u de {filepath}", border_style="yellow"))
        except Exception as e:
            console.print(f"[red]Erreur lors de l'affichage avec le pager : {e}[/red]")


    def edit_file(self, filepath: Path):
        """Session d'Ã©dition interactive d'un fichier."""
        full_path = self.working_directory / filepath
        success, original_content = self.file_handler.read_file(full_path)

        if not success:
            console.print(f"[red]Impossible de lire le fichier : {original_content}[/red]")
            return

        console.print(f"[cyan]Ã‰dition de : {filepath}[/cyan]")
        edit_request = Prompt.ask("[bold]DÃ©crivez les changements souhaitÃ©s[/bold]")

        prompt = f"""L'utilisateur souhaite modifier le fichier '{filepath}'.
Voici le contenu original :
    {original_content}
Voici la demande de l'utilisateur : "{edit_request}".

Veuillez fournir la rÃ©ponse en utilisant le format <file_modifications> avec le contenu complet et mis Ã  jour du fichier."""

        system_prompt = self.api.get_system_prompt(list(self.loaded_files.keys()))
        response = self.api.generate(prompt, system_prompt, self.context)
        self.process_response(response)

    def run_command(self, command: str):
        console.print(f"[bold cyan]ExÃ©cution : $ {command}[/bold cyan]")
        try:
            with subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, cwd=self.working_directory) as proc:
                if proc.stdout:
                    for line in proc.stdout:
                        console.print(f"[dim]{line.strip()}[/dim]")
                if proc.stderr:
                    for line in proc.stderr:
                        console.print(f"[red]{line.strip()}[/red]")
        except Exception as e:
            console.print(f"[red]Erreur d'exÃ©cution : {e}[/red]")

    def list_loaded_files(self):
        if not self.loaded_files:
            console.print("[dim]Aucun fichier chargÃ©.[/dim]")
            return

        table = Table(title=" Fichiers en Contexte", border_style="purple")
        table.add_column("Chemin", style="cyan")
        table.add_column("Taille (caractÃ¨res)", style="green")

        for filepath, content in self.loaded_files.items():
            table.add_row(filepath, str(len(content)))
        console.print(table)

    def change_directory(self, new_dir: Path):
        """Change le rÃ©pertoire de travail."""
        try:
            target_path = (self.working_directory / new_dir).resolve()
            if target_path.is_dir():
                os.chdir(target_path)
                self.working_directory = target_path
                console.print(f"[green]Nouveau rÃ©pertoire : {self.working_directory}[/green]")
            else:
                console.print(f"[red]RÃ©pertoire non trouvÃ© : {target_path}[/red]")
        except Exception as e:
            console.print(f"[red]Erreur : {e}[/red]")

    def guess_lexer(self, filepath: Path, code: str = "") -> str:
        return Syntax.guess_lexer(str(filepath), code=code)

    def get_pasted_input(self) -> str:
        """RÃ©cupÃ¨re une saisie multiligne de l'utilisateur de maniÃ¨re fiable."""
        console.print("[dim]Mode collage activÃ©. Collez votre texte ci-dessous.[/dim]")
        console.print("[dim]Appuyez sur [bold]Ctrl+D[/bold] (Linux/macOS) ou [bold]Ctrl+Z puis EntrÃ©e[/bold] (Windows) pour terminer la saisie.[/dim]")

        lines = []
        try:
            while True:
                line = sys.stdin.readline()
                if not line:  # EOF (Ctrl+D/Ctrl+Z)
                    break
                lines.append(line)
        except KeyboardInterrupt: # Permet d'annuler avec Ctrl+C
            console.print("\n[yellow]Saisie multiligne annulÃ©e.[/yellow]")
            return ""

        pasted_text = "".join(lines).strip()

        if pasted_text:
            lexer = self.guess_lexer(Path("pasted.txt"), code=pasted_text)
            console.print(Panel(
                Syntax(pasted_text, lexer, theme="monokai", line_numbers=True),
                title="Texte collÃ© et envoyÃ© Ã  l'IA",
                border_style="green"
            ))
        else:
            console.print("[yellow]Aucune saisie dÃ©tectÃ©e.[/yellow]")

        return pasted_text

    def process_response(self, response: str):
        """Analyse la rÃ©ponse de l'IA pour des actions spÃ©ciales (crÃ©ation/modification de fichiers)."""
        try:
            if '<file_modifications>' in response:
                self.handle_file_modifications(response)
            elif '<plan>' in response and '<code>' in response:
                self.handle_file_creation(response)
            else:
                pass # La rÃ©ponse est dÃ©jÃ  affichÃ©e par le stream
        except Exception as e:
            console.print(f"[bold red]Erreur lors de l'analyse de la rÃ©ponse de l'IA :[/bold red] {e}")
            console.print("[dim]Affichage de la rÃ©ponse brute :[/dim]")
            console.print(response)

    def handle_file_modifications(self, response: str):
        """GÃ¨re la logique de modification de fichiers proposÃ©e par l'IA."""
        console.print("[bold yellow]L'assistant propose des modifications de fichiers...[/bold yellow]")
        try:
            # Enveloppe la rÃ©ponse dans une balise racine pour un parsing XML valide, mÃªme si elle est fragmentÃ©e.
            xml_response = f"<root>{response}</root>"
            root = ET.fromstring(xml_response)

            modifications = []
            for file_elem in root.findall('.//file'):
                filepath_str = file_elem.get('path')
                content = (file_elem.text or "").strip()
                if filepath_str and content:
                    modifications.append({'path': Path(filepath_str), 'content': content})

            if not modifications:
                console.print("[red]L'IA a tentÃ© de modifier un fichier mais le format Ã©tait incorrect.[/red]")
                return

            for mod in modifications:
                full_path = self.working_directory / mod['path']
                original_content = ""
                if full_path.exists():
                    _, original_content = self.file_handler.read_file(full_path)
                self.file_handler.show_diff(original_content, mod['content'], str(mod['path']))

            if Confirm.ask("\n[bold]Appliquer ces modifications ?[/bold]", default=True):
                for mod in modifications:
                    success, msg = self.file_handler.write_file(self.working_directory / mod['path'], mod['content'])
                    if success:
                        console.print(f"[green]âœ“ {msg}[/green]")
                        self.loaded_files[str(mod['path'])] = mod['content']
                    else:
                        console.print(f"[red]âœ— Erreur sur {mod['path']}: {msg}[/red]")
            else:
                console.print("[yellow]Modifications annulÃ©es.[/yellow]")

        except ET.ParseError:
             console.print("[red]Erreur de parsing XML. L'IA n'a pas respectÃ© le format demandÃ©.[/red]")
             console.print("[dim]RÃ©ponse brute de l'IA :[/dim]")
             console.print(response)


    def handle_file_creation(self, response: str):
        """GÃ¨re la logique de crÃ©ation de fichier."""
        plan_match = re.search(r'<plan>(.*?)</plan>', response, re.DOTALL)
        code_match = re.search(r'<code>(.*?)</code>', response, re.DOTALL)

        if not (plan_match and code_match): return

        plan = plan_match.group(1).strip()
        code = code_match.group(1).strip()

        console.print(Panel(Markdown(plan), title="Plan de CrÃ©ation ProposÃ©", border_style="blue"))

        if Confirm.ask("\n[bold]ProcÃ©der Ã  la crÃ©ation de ce fichier ?[/bold]"):
            filename_match = re.search(r'filename:\s*(\S+)', plan, re.IGNORECASE)
            default_filename = filename_match.group(1) if filename_match else "nouveau_fichier.py"

            filename_str = Prompt.ask("Nom du fichier", default=default_filename)
            filepath = self.working_directory / filename_str

            success, msg = self.file_handler.write_file(filepath, code)
            if success:
                console.print(f"[green]âœ“ {msg}[/green]")
                if Confirm.ask("Charger ce nouveau fichier en contexte ?", default=True):
                    self.load_file(Path(filename_str))
            else:
                console.print(f"[red]âœ— {msg}[/red]")
        else:
            console.print("[yellow]CrÃ©ation annulÃ©e.[/yellow]")

    def chat_loop(self):
        """Boucle principale de chat."""
        header = Text(ASCII_LOGO, style="bold cyan", justify="center")
        welcome_panel = Panel(
            header,
            title="Ollama CLI v3",
            subtitle="[dim]Tapez [yellow]/help[/yellow] pour les commandes.[/dim]",
            border_style="cyan"
        )
        console.print(welcome_panel)

        if not self.select_model():
            return

        self.load_context()

        while True:
            try:
                prompt_text = self.build_full_prompt()
                user_input = console.input(prompt_text)

                if not user_input.strip():
                    continue

                if user_input.startswith('/'):
                    continue_loop, processed_input = self.handle_command(user_input)

                    if not continue_loop:
                        self.save_context()
                        break

                    if processed_input is not None:
                        user_input = processed_input
                        if not user_input:
                            continue
                    else:
                        continue

                console.clear()
                console.print(welcome_panel)
                console.print(f"{prompt_text}{user_input}") # Affiche le prompt de l'utilisateur

                self.conversation_history.append(("user", user_input))

                full_content_prompt = self.get_files_content_for_prompt() + user_input
                system_prompt = self.api.get_system_prompt(list(self.loaded_files.keys()))

                response = self.api.generate(full_content_prompt, system_prompt, self.context)
                self.process_response(response)

                self.conversation_history.append(("assistant", response))
                self.save_context()

            except (KeyboardInterrupt, EOFError):
                self.save_context()
                console.print("\n[yellow]Au revoir ![/yellow]")
                break

    def build_full_prompt(self) -> str:
        """Construit le prompt affichÃ© Ã  l'utilisateur, incluant le contexte."""
        return "\n[bold green]Vous[/bold green] > "

    def get_files_content_for_prompt(self) -> str:
        """ConcatÃ¨ne le contenu des fichiers chargÃ©s pour l'injecter dans le prompt."""
        if not self.loaded_files:
            return ""

        context_str = "CONTEXTE :\n"
        for path, content in self.loaded_files.items():
            context_str += f"--- Contenu de {path} ---\n{content}\n--- Fin de {path} ---\n\n"
        return context_str


def main():
    parser = argparse.ArgumentParser(description="Ollama CLI v3 - Assistant de code interactif.")
    parser.add_argument("--api-url", default="http://localhost:11434", help="URL de l'API Ollama.")
    parser.add_argument("--model", help="SpÃ©cifier un modÃ¨le Ã  utiliser directement.")
    parser.add_argument("files", nargs="*", help="Fichiers Ã  charger au dÃ©marrage.")
    args = parser.parse_args()

    cli = OllamaCLI()
    cli.api.base_url = args.api_url
    if args.model:
        cli.api.model = args.model

    if args.files:
        for f in args.files:
            cli.load_file(Path(f))

    cli.chat_loop()

if __name__ == "__main__":
    main()
